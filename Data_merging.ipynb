{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKz3bHaURCg+C3M74N+H+Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clementh626/ANLP-Project/blob/main/Data_merging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gkr8wmyaESLa",
        "outputId": "ca11b72c-c5fb-4c7a-e003-f2f345f69fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List all files in 'My Drive'\n",
        "drive_path = '/content/drive/My Drive/anlp_project/1_collect/data/collect/winson/data_fa23'\n",
        "for root, dirs, files in os.walk(drive_path):\n",
        "    print(root, dirs, files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NZ9IW7rEo-J",
        "outputId": "15d7203f-c090-4291-92cc-556c8f2c3b6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/anlp_project/1_collect/data/collect/winson/data_fa23 [] ['Aviation_content.csv', 'Business-Development_content.csv', 'Communications_main_comments.csv', 'Ask-Blinders_content.csv', 'Aviation_main_comments.csv', 'Auto_sub_comments.csv', 'Business-Development_main_comments.csv', 'Business-Development_sub_comments.csv', 'Communications_content.csv', 'Ask-Blinders_sub_comments.csv', 'Aviation_sub_comments.csv', 'Communications_sub_comments.csv', 'Auto_main_comments.csv', 'Auto_content.csv', 'Ask-Blinders_main_comments.csv', 'Corporate-Finance_sub_comments.csv', 'Corporate-Finance_content.csv', 'Data-Science_main_comments.csv', 'Corporate-Finance_main_comments.csv', 'Data-Science_content.csv', 'Design_content.csv', 'Data-Science_sub_comments.csv', 'Design_sub_comments.csv', 'Design_main_comments.csv', 'Financial-Services_main_comments.csv', 'E-Commerce-Retail_sub_comments.csv', 'E-Commerce-Retail_main_comments.csv', 'E-Commerce-Retail_content.csv', 'Gaming_main_comments.csv', 'Food-Dining_content.csv', 'Financial-Services_content.csv', 'Financial-Services_sub_comments.csv', 'Food-Dining_main_comments.csv', 'Fitness-Nutrition_sub_comments.csv', 'Food-Dining_sub_comments.csv', 'Fitness-Nutrition_main_comments.csv', 'Fitness-Nutrition_content.csv', 'Gaming_sub_comments.csv', 'Gaming_content.csv', 'Hardware-Engineering_main_comments.csv', 'Housing_sub_comments.csv', 'Housing_content.csv', 'Housing_main_comments.csv', 'Hardware_content.csv', 'Hardware_main_comments.csv', 'Hardware_sub_comments.csv', 'Healthcare_sub_comments.csv', 'Hardware-Engineering_content.csv', 'Healthcare_content.csv', 'Healthcare_main_comments.csv', 'Hardware-Engineering_sub_comments.csv', 'Human-Resources_content.csv', 'Human-Resources_sub_comments.csv', 'HR-Issues_main_comments.csv', 'Human-Resources_main_comments.csv', 'HR-Issues_sub_comments.csv', 'HR-Issues_content.csv', 'Industries_main_comments.csv', 'Industries_content.csv', 'Information-Technology_main_comments.csv', 'Industries_sub_comments.csv', 'Investments-Money_sub_comments.csv', 'Investment-Banking-Sell-Side_sub_comments.csv', 'Investments-Money_content.csv', 'Investments-Money_main_comments.csv', 'Investment-Banking-Sell-Side_content.csv', 'Investment-Banking-Sell-Side_main_comments.csv', 'Information-Technology_sub_comments.csv', 'Information-Technology_content.csv', 'Job-Groups_main_comments.csv', 'Layoffs_content.csv', 'Job-Groups_sub_comments.csv', 'Job-Groups_content.csv', 'Job-Openings_sub_comments.csv', 'Legal_sub_comments.csv', 'Layoffs_main_comments.csv', 'Legal_content.csv', 'Job-Openings_main_comments.csv', 'Layoffs_sub_comments.csv', 'Legal_main_comments.csv', 'Management-Consulting_content.csv', 'Marketing_content.csv', 'Job-Openings_content.csv', 'Media-Entertainment_content.csv', 'Management-Consulting_sub_comments.csv', 'Marketing_main_comments.csv', 'Marketing_sub_comments.csv', 'Media-Entertainment_main_comments.csv', 'Management-Consulting_main_comments.csv', 'Media-Entertainment_sub_comments.csv', 'Misc_main_comments.csv', 'Misc_sub_comments.csv', 'Misc_content.csv', 'Mental-Health_sub_comments.csv', 'Mental-Health_content.csv', 'Pets_content.csv', 'Operations_main_comments.csv', 'Private-Equity-Buy-Side_content.csv', 'Operations_content.csv', 'Politics_main_comments.csv', 'Office-Life_sub_comments.csv', 'Private-Equity-Buy-Side_main_comments.csv', 'Referrals_main_comments.csv', 'Mental-Health_main_comments.csv', 'Operations_sub_comments.csv', 'Office-Life_content.csv', 'Pets_main_comments.csv', 'Private-Equity-Buy-Side_sub_comments.csv', 'Politics_sub_comments.csv', 'Politics_content.csv', 'Pets_sub_comments.csv', 'Office-Life_main_comments.csv', 'Relationships_sub_comments.csv', 'Referrals_content.csv', 'Referrals_sub_comments.csv', 'Relationships_content.csv', 'Product-Management_sub_comments.csv', 'Relationships_main_comments.csv', 'Product-Management_main_comments.csv', 'Return-to-Office_main_comments.csv', 'Sales_main_comments.csv', 'Sales_sub_comments.csv', 'Return-to-Office_content.csv', 'Sales_content.csv', 'Return-to-Office_sub_comments.csv', 'Product-Management_content.csv', 'Security_content.csv', 'Security_main_comments.csv', 'Security_sub_comments.csv', 'Software-Engineering_content.csv', 'Startups_main_comments.csv', 'Supply-Chain_sub_comments.csv', 'Supply-Chain_content.csv', 'Software-Engineering_main_comments.csv', 'Startups_content.csv', 'Software-Engineering_sub_comments.csv', 'Supply-Chain_main_comments.csv', 'Startups_sub_comments.csv', 'Telecom_content.csv', 'Telecom_main_comments.csv', 'Telecom_sub_comments.csv', 'Tech_sub_comments.csv', 'Tech_main_comments.csv', 'Timea_processed_hr_issues_sub_comments.csv', 'Today-I-Learned_main_comments.csv', 'Tech_content.csv', 'Today-I-Learned_content.csv', 'Today-I-Learned_sub_comments.csv', 'Timea_processed_hr_issues_content.csv', 'Timea_processed_hr_issues_main_comments.csv', 'Travel_content.csv', 'Work-Memes_content.csv', 'Travel_sub_comments.csv', 'Travel_main_comments.csv', 'Work-From-Home_content.csv', 'Work-Memes_main_comments.csv', 'Work-Visa_sub_comments.csv', 'Work-From-Home_sub_comments.csv', 'Work-Visa_content.csv', 'Work-Memes_sub_comments.csv', 'Work-Visa_main_comments.csv', 'Working-Parents_content.csv', 'Work-From-Home_main_comments.csv', 'Working-Parents_main_comments.csv', 'Working-Parents_sub_comments.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Define the path to your files\n",
        "path = '/content/drive/My Drive/anlp_project/1_collect/data/collect/winson/data_fa23'\n",
        "path2 = '/content/drive/My Drive/anlp_project/1_collect/data/collect/data/teamblind'\n",
        "\n",
        "# Combine all content files\n",
        "content_files = glob.glob(f\"{path}/*_content.csv\")\n",
        "content_df = pd.concat([pd.read_csv(file) for file in content_files], ignore_index=True)\n",
        "content_df.to_csv(f\"{path2}/Combined_Content.csv\", index=False)\n",
        "\n",
        "# Combine all main comments files\n",
        "main_comments_files = glob.glob(f\"{path}/*_main_comments.csv\")\n",
        "main_comments_df = pd.concat([pd.read_csv(file) for file in main_comments_files], ignore_index=True)\n",
        "main_comments_df.to_csv(f\"{path2}/Combined_Main_Comments.csv\", index=False)\n",
        "\n",
        "# Combine all sub-comments files\n",
        "sub_comments_files = glob.glob(f\"{path}/*_sub_comments.csv\")\n",
        "sub_comments_df = pd.concat([pd.read_csv(file) for file in sub_comments_files], ignore_index=True)\n",
        "sub_comments_df.to_csv(f\"{path2}/Combined_Sub_Comments.csv\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "0ZpSdX54FQ_X"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define the function to convert HTML to plain text, handling non-string input\n",
        "def html_to_text(html_content):\n",
        "    if isinstance(html_content, str):  # Process only if content is a string\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "        return soup.get_text()\n",
        "    return html_content  # Return as is if the content is not a string\n",
        "\n",
        "# Paths to the combined CSV files\n",
        "combined_content_path = f\"{path2}/Combined_Content.csv\"\n",
        "\n",
        "# Read the combined content CSV and convert HTML to text\n",
        "content_df = pd.read_csv(combined_content_path)\n",
        "content_df['Content'] = content_df['Content'].apply(html_to_text)\n",
        "content_df.to_csv(combined_content_path, index=False)\n",
        "\n",
        "# Paths to the combined CSV files\n",
        "combined_main_comments_path = f\"{path2}/Combined_Main_Comments.csv\"\n",
        "combined_sub_comments_path = f\"{path2}/Combined_Sub_Comments.csv\"\n",
        "\n",
        "# Read the combined main comments CSV and convert HTML to text\n",
        "main_comments_df = pd.read_csv(combined_main_comments_path)\n",
        "main_comments_df['Comment'] = main_comments_df['Comment'].apply(html_to_text)\n",
        "main_comments_df.to_csv(combined_main_comments_path, index=False)\n",
        "\n",
        "# Read the combined sub-comments CSV and convert HTML to text\n",
        "sub_comments_df = pd.read_csv(combined_sub_comments_path)\n",
        "sub_comments_df['Sub Comment'] = sub_comments_df['Sub Comment'].apply(html_to_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsQr6Q9jZeUY",
        "outputId": "4ab6172a-5949-4323-cc9f-a420aa59ba08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-5bb20ac2087b>:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(html_content, 'html.parser')\n",
            "<ipython-input-7-5bb20ac2087b>:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(html_content, 'html.parser')\n",
            "<ipython-input-7-5bb20ac2087b>:7: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  soup = BeautifulSoup(html_content, 'html.parser')\n"
          ]
        }
      ]
    }
  ]
}